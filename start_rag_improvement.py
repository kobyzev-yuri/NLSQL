#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞ —Ä–∞–±–æ—Ç –ø–æ —É–ª—É—á—à–µ–Ω–∏—é RAG
–ó–∞–ø—É—Å–∫–∞–µ—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É –∏ —Å–æ–∑–¥–∞–µ—Ç baseline –º–µ—Ç—Ä–∏–∫–∏
"""

import asyncio
import json
import time
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from src.services.query_service import QueryService
from src.vanna.vanna_semantic_fixed import create_semantic_vanna_client
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class RAGDiagnostic:
    def __init__(self):
        self.results = {
            'timestamp': time.time(),
            'baseline_metrics': {},
            'issues_found': [],
            'recommendations': []
        }
    
    async def run_full_diagnostic(self):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ RAG —Å–∏—Å—Ç–µ–º—ã"""
        logger.info("üîç –ó–∞–ø—É—Å–∫ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ RAG —Å–∏—Å—Ç–µ–º—ã...")
        
        # 1. –¢–µ—Å—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
        await self.test_semantic_search()
        
        # 2. –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        await self.analyze_context_quality()
        
        # 3. –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SQL
        await self.test_sql_generation()
        
        # 4. –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        await self.analyze_performance()
        
        # 5. –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        self.create_report()
        
        logger.info("‚úÖ –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ rag_diagnostic_report.json")
    
    async def test_semantic_search(self):
        """–¢–µ—Å—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
        logger.info("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞...")
        
        try:
            semantic_client = create_semantic_vanna_client()
            
            test_questions = [
                "–ø–æ–∫–∞–∂–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π",
                "—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ—Ç–¥–µ–ª–∞–º", 
                "–ø–ª–∞—Ç–µ–∂–∏ –∑–∞ –º–µ—Å—è—Ü"
            ]
            
            search_results = {}
            for question in test_questions:
                logger.info(f"  –¢–µ—Å—Ç–∏—Ä—É–µ–º: {question}")
                
                # –¢–µ—Å—Ç DDL –ø–æ–∏—Å–∫–∞
                ddl_results = await semantic_client.get_related_ddl(question)
                logger.info(f"    DDL —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(ddl_results)}")
                
                # –¢–µ—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
                doc_results = await semantic_client.get_related_documentation(question)
                logger.info(f"    –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: {len(doc_results)}")
                
                # –¢–µ—Å—Ç Q&A
                qa_results = await semantic_client.get_similar_question_sql(question)
                logger.info(f"    Q&A –ø–∞—Ä: {len(qa_results)}")
                
                search_results[question] = {
                    'ddl_count': len(ddl_results),
                    'doc_count': len(doc_results),
                    'qa_count': len(qa_results),
                    'ddl_results': ddl_results[:3],  # –ü–µ—Ä–≤—ã–µ 3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                    'doc_results': doc_results[:3],
                    'qa_results': qa_results[:3]
                }
            
            self.results['semantic_search'] = search_results
            
            # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º
            total_ddl = sum(r['ddl_count'] for r in search_results.values())
            if total_ddl == 0:
                self.results['issues_found'].append("–ö–†–ò–¢–ò–ß–ù–û: DDL –ø–æ–∏—Å–∫ –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                self.results['recommendations'].append("–ò—Å–ø—Ä–∞–≤–∏—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ DDL")
            
            if total_ddl < len(test_questions):
                self.results['issues_found'].append("–ü–†–û–ë–õ–ï–ú–ê: DDL –ø–æ–∏—Å–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç —á–∞—Å—Ç–∏—á–Ω–æ")
                self.results['recommendations'].append("–£–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è DDL")
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}")
            self.results['issues_found'].append(f"–û–®–ò–ë–ö–ê: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç - {e}")
    
    async def analyze_context_quality(self):
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        logger.info("üìä –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞...")
        
        try:
            query_service = QueryService()
            
            test_questions = [
                "–ø–æ–∫–∞–∂–∏ –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π",
                "—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ—Ç–¥–µ–ª–∞–º",
                "–ø–ª–∞—Ç–µ–∂–∏ –ø–æ –∫–ª–∏–µ–Ω—Ç–∞–º"
            ]
            
            context_analysis = {}
            for question in test_questions:
                logger.info(f"  –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è: {question}")
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º SQL –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
                start_time = time.time()
                sql = await query_service.generate_sql(question, {})
                end_time = time.time()
                
                # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–ø—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞)
                context_size = len(question) + len(sql) + 1000  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
                
                context_analysis[question] = {
                    'response_time': end_time - start_time,
                    'sql_generated': sql,
                    'context_size_estimate': context_size,
                    'sql_quality': self.analyze_sql_quality(sql)
                }
            
            self.results['context_analysis'] = context_analysis
            
            # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º
            avg_response_time = sum(r['response_time'] for r in context_analysis.values()) / len(context_analysis)
            if avg_response_time > 30:
                self.results['issues_found'].append(f"–ú–ï–î–õ–ï–ù–ù–û: –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ {avg_response_time:.1f}—Å")
                self.results['recommendations'].append("–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å")
            
            avg_context_size = sum(r['context_size_estimate'] for r in context_analysis.values()) / len(context_analysis)
            if avg_context_size > 4000:
                self.results['issues_found'].append(f"–ë–û–õ–¨–®–û–ô –ö–û–ù–¢–ï–ö–°–¢: –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä {avg_context_size:.0f} —Ç–æ–∫–µ–Ω–æ–≤")
                self.results['recommendations'].append("–£–º–µ–Ω—å—à–∏—Ç—å —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}")
            self.results['issues_found'].append(f"–û–®–ò–ë–ö–ê: –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç - {e}")
    
    async def test_sql_generation(self):
        """–¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SQL"""
        logger.info("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SQL...")
        
        try:
            query_service = QueryService()
            
            test_cases = [
                {
                    'question': '–ø–æ–∫–∞–∂–∏ –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π',
                    'expected_tables': ['equsers'],
                    'expected_complexity': 'simple'
                },
                {
                    'question': '—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ—Ç–¥–µ–ª–∞–º',
                    'expected_tables': ['equsers', 'eq_departments'],
                    'expected_complexity': 'complex'
                },
                {
                    'question': '–ø–ª–∞—Ç–µ–∂–∏ –ø–æ –∫–ª–∏–µ–Ω—Ç–∞–º',
                    'expected_tables': ['equsers', 'payments'],
                    'expected_complexity': 'complex'
                }
            ]
            
            sql_test_results = {}
            for test_case in test_cases:
                logger.info(f"  –¢–µ—Å—Ç–∏—Ä—É–µ–º: {test_case['question']}")
                
                sql = await query_service.generate_sql(test_case['question'], {})
                
                # –ê–Ω–∞–ª–∏–∑ SQL
                sql_analysis = {
                    'sql': sql,
                    'quality_score': self.analyze_sql_quality(sql),
                    'has_expected_tables': self.check_expected_tables(sql, test_case['expected_tables']),
                    'has_invented_tables': self.check_invented_tables(sql),
                    'complexity_match': self.check_complexity(sql, test_case['expected_complexity'])
                }
                
                sql_test_results[test_case['question']] = sql_analysis
                
                logger.info(f"    –ö–∞—á–µ—Å—Ç–≤–æ: {sql_analysis['quality_score']}/5")
                logger.info(f"    –û–∂–∏–¥–∞–µ–º—ã–µ —Ç–∞–±–ª–∏—Ü—ã: {sql_analysis['has_expected_tables']}")
                logger.info(f"    –ò–∑–æ–±—Ä–µ—Ç–µ–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã: {sql_analysis['has_invented_tables']}")
            
            self.results['sql_generation'] = sql_test_results
            
            # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º
            invented_tables_count = sum(1 for r in sql_test_results.values() if r['has_invented_tables'])
            if invented_tables_count > 0:
                self.results['issues_found'].append(f"–ü–†–û–ë–õ–ï–ú–ê: {invented_tables_count} –∑–∞–ø—Ä–æ—Å–æ–≤ —Å–æ–¥–µ—Ä–∂–∞—Ç –∏–∑–æ–±—Ä–µ—Ç–µ–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã")
                self.results['recommendations'].append("–£–ª—É—á—à–∏—Ç—å –ø–æ–∏—Å–∫ DDL –∏ —Å—Ö–µ–º—É –ë–î")
            
            avg_quality = sum(r['quality_score'] for r in sql_test_results.values()) / len(sql_test_results)
            if avg_quality < 5:
                self.results['issues_found'].append(f"–ù–ò–ó–ö–û–ï –ö–ê–ß–ï–°–¢–í–û: –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ {avg_quality:.1f}/5")
                self.results['recommendations'].append("–î–æ–±–∞–≤–∏—Ç—å few-shot –ø—Ä–∏–º–µ—Ä—ã –∏ —É–ª—É—á—à–∏—Ç—å –ø—Ä–æ–º–ø—Ç—ã")
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è SQL: {e}")
            self.results['issues_found'].append(f"–û–®–ò–ë–ö–ê: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è SQL –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç - {e}")
    
    async def analyze_performance(self):
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        logger.info("‚ö° –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
        
        try:
            query_service = QueryService()
            
            # –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            test_question = "–ø–æ–∫–∞–∂–∏ –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"
            times = []
            
            for i in range(3):
                start_time = time.time()
                await query_service.generate_sql(test_question, {})
                end_time = time.time()
                times.append(end_time - start_time)
                logger.info(f"  –ü–æ–ø—ã—Ç–∫–∞ {i+1}: {times[-1]:.1f}—Å")
            
            avg_time = sum(times) / len(times)
            min_time = min(times)
            max_time = max(times)
            
            self.results['performance'] = {
                'avg_response_time': avg_time,
                'min_response_time': min_time,
                'max_response_time': max_time,
                'all_times': times
            }
            
            # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            if avg_time > 30:
                self.results['issues_found'].append(f"–ú–ï–î–õ–ï–ù–ù–û: –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è {avg_time:.1f}—Å")
                self.results['recommendations'].append("–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å")
            
            if max_time - min_time > 20:
                self.results['issues_found'].append("–ù–ï–°–¢–ê–ë–ò–õ–¨–ù–û: –ë–æ–ª—å—à–æ–π —Ä–∞–∑–±—Ä–æ—Å –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞")
                self.results['recommendations'].append("–°—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å")
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")
            self.results['issues_found'].append(f"–û–®–ò–ë–ö–ê: –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç - {e}")
    
    def analyze_sql_quality(self, sql):
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ SQL"""
        if not sql or not sql.strip():
            return 0
        
        sql_lower = sql.lower().strip()
        
        # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        if not sql_lower.startswith('select'):
            return 0
        
        # –®—Ç—Ä–∞—Ñ—ã
        penalty = 0
        if 'eqorders' in sql_lower or 'eqpayments' in sql_lower:
            penalty += 1
        
        # –ë–æ–Ω—É—Å—ã
        bonus = 0
        if 'join' in sql_lower:
            bonus += 1
        if 'group by' in sql_lower:
            bonus += 1
        if 'where' in sql_lower:
            bonus += 1
        if 'count(' in sql_lower or 'sum(' in sql_lower:
            bonus += 1
        
        return max(0, 5 - penalty + bonus)
    
    def check_expected_tables(self, sql, expected_tables):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –æ–∂–∏–¥–∞–µ–º—ã—Ö —Ç–∞–±–ª–∏—Ü"""
        sql_lower = sql.lower()
        return any(table.lower() in sql_lower for table in expected_tables)
    
    def check_invented_tables(self, sql):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∏–∑–æ–±—Ä–µ—Ç–µ–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã"""
        sql_lower = sql.lower()
        invented_tables = ['eqorders', 'eqpayments', 'payments']
        return any(table in sql_lower for table in invented_tables)
    
    def check_complexity(self, sql, expected_complexity):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏"""
        sql_lower = sql.lower()
        
        if expected_complexity == 'simple':
            return not ('join' in sql_lower or 'group by' in sql_lower)
        elif expected_complexity == 'complex':
            return 'join' in sql_lower or 'group by' in sql_lower
        
        return True
    
    def create_report(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞"""
        logger.info("üìù –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞...")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        with open('rag_diagnostic_report.json', 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        report_lines = [
            "# RAG Diagnostic Report",
            f"Generated: {time.strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "## Issues Found:",
        ]
        
        if self.results['issues_found']:
            for issue in self.results['issues_found']:
                report_lines.append(f"- {issue}")
        else:
            report_lines.append("- No critical issues found")
        
        report_lines.extend([
            "",
            "## Recommendations:",
        ])
        
        if self.results['recommendations']:
            for rec in self.results['recommendations']:
                report_lines.append(f"- {rec}")
        else:
            report_lines.append("- No specific recommendations")
        
        report_lines.extend([
            "",
            "## Next Steps:",
            "1. Review the detailed JSON report: rag_diagnostic_report.json",
            "2. Address critical issues first",
            "3. Implement recommendations",
            "4. Re-run diagnostic to verify improvements",
            "",
            "## Files to Check:",
            "- src/vanna/vanna_semantic_fixed.py (DDL search)",
            "- src/services/query_service.py (Context optimization)",
            "- src/vanna/optimized_dual_pipeline.py (Few-shot learning)"
        ])
        
        with open('rag_diagnostic_report.md', 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))
        
        logger.info("üìä –û—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω:")
        logger.info("  - rag_diagnostic_report.json (–¥–µ—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)")
        logger.info("  - rag_diagnostic_report.md (–∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç)")

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –ó–∞–ø—É—Å–∫ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ RAG —Å–∏—Å—Ç–µ–º—ã...")
    print("=" * 50)
    
    diagnostic = RAGDiagnostic()
    await diagnostic.run_full_diagnostic()
    
    print("\n" + "=" * 50)
    print("‚úÖ –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print("üìã –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª—ã:")
    print("  - rag_diagnostic_report.json")
    print("  - rag_diagnostic_report.md")
    print("  - TOMORROW_RAG_IMPROVEMENT_PLAN.md")
    print("  - RAG_IMPROVEMENT_CHECKLIST.md")

if __name__ == "__main__":
    asyncio.run(main())




