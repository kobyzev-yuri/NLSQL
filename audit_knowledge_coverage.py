#!/usr/bin/env python3
"""
–ê—É–¥–∏—Ç –ø–æ–∫—Ä—ã—Ç–∏—è –∑–Ω–∞–Ω–∏–π –≤ RAG —Å–∏—Å—Ç–µ–º–µ
"""

import asyncio
import asyncpg
import os
import logging
import json
from typing import List, Dict, Any, Set
from collections import defaultdict

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class KnowledgeCoverageAuditor:
    """–ê—É–¥–∏—Ç–æ—Ä –ø–æ–∫—Ä—ã—Ç–∏—è –∑–Ω–∞–Ω–∏–π"""
    
    def __init__(self):
        self.database_url = "postgresql://postgres:1234@localhost:5432/test_docstructure"
    
    async def audit_vector_db_coverage(self):
        """–ê—É–¥–∏—Ç –ø–æ–∫—Ä—ã—Ç–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î"""
        print("üîç –ê—É–¥–∏—Ç –ø–æ–∫—Ä—ã—Ç–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î...")
        
        conn = await asyncpg.connect(self.database_url)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        content_stats = await conn.fetch("""
            SELECT content_type, COUNT(*) as count, 
                   COUNT(CASE WHEN embedding IS NOT NULL THEN 1 END) as with_embedding
            FROM vanna_vectors 
            GROUP BY content_type 
            ORDER BY count DESC
        """)
        
        print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –∫–æ–Ω—Ç–µ–Ω—Ç–∞:")
        for stat in content_stats:
            print(f"  {stat['content_type']}: {stat['count']} –∑–∞–ø–∏—Å–µ–π ({stat['with_embedding']} —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏)")
        
        # –ê–Ω–∞–ª–∏–∑ DDL –ø–æ–∫—Ä—ã—Ç–∏—è
        ddl_content = await conn.fetch("SELECT content FROM vanna_vectors WHERE content_type = 'ddl'")
        ddl_text = "\n".join([row['content'] for row in ddl_content])
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ç–∞–±–ª–∏—Ü—ã –∏–∑ –ë–î
        db_tables = await conn.fetch("""
            SELECT table_name 
            FROM information_schema.tables 
            WHERE table_schema = 'public' 
            AND table_type = 'BASE TABLE'
            ORDER BY table_name
        """)
        
        db_table_names = {row['table_name'] for row in db_tables}
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ DDL
        covered_tables = set()
        for table_name in db_table_names:
            if table_name in ddl_text:
                covered_tables.add(table_name)
        
        missing_tables = db_table_names - covered_tables
        
        print(f"\nüìä –ü–æ–∫—Ä—ã—Ç–∏–µ DDL:")
        print(f"  –í—Å–µ–≥–æ —Ç–∞–±–ª–∏—Ü –≤ –ë–î: {len(db_table_names)}")
        print(f"  –ü–æ–∫—Ä—ã—Ç–æ DDL: {len(covered_tables)} ({len(covered_tables)/len(db_table_names)*100:.1f}%)")
        print(f"  –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ DDL: {len(missing_tables)}")
        
        # –§–æ–∫—É—Å–∏—Ä—É–µ–º—Å—è –Ω–∞ –ø–ª–∞—Ç–µ–∂–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü–∞—Ö
        payment_tables = {t for t in db_table_names if 'payment' in t.lower() or 'tbl_' in t.lower()}
        payment_covered = payment_tables & covered_tables
        payment_missing = payment_tables - covered_tables
        
        print(f"\nüí∞ –ü–æ–∫—Ä—ã—Ç–∏–µ –ø–ª–∞—Ç–µ–∂–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü:")
        print(f"  –ü–ª–∞—Ç–µ–∂–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã –≤ –ë–î: {len(payment_tables)}")
        print(f"  –ü–æ–∫—Ä—ã—Ç–æ DDL: {len(payment_covered)}")
        print(f"  –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ DDL: {len(payment_missing)}")
        
        if payment_missing:
            print(f"  –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–ª–∞—Ç–µ–∂–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã:")
            for table in sorted(payment_missing):
                print(f"    - {table}")
        
        await conn.close()
        
        return {
            'content_stats': [dict(stat) for stat in content_stats],
            'total_tables': len(db_table_names),
            'covered_tables': len(covered_tables),
            'missing_tables': list(missing_tables),
            'payment_tables': list(payment_tables),
            'payment_covered': len(payment_covered),
            'payment_missing': list(payment_missing)
        }
    
    async def audit_docstructure_schema(self):
        """–ê—É–¥–∏—Ç DocStructureSchema (JSON/XML –æ—Ç –∑–∞–∫–∞–∑—á–∏–∫–∞)"""
        print("\nüîç –ê—É–¥–∏—Ç DocStructureSchema...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ DocStructureSchema
        docstructure_files = []
        docstructure_dir = "/mnt/ai/cnn/sql4A/DocStructureSchema"
        
        if os.path.exists(docstructure_dir):
            for file in os.listdir(docstructure_dir):
                if file.endswith(('.json', '.xml')):
                    docstructure_files.append(file)
        
        print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ DocStructureSchema: {len(docstructure_files)}")
        for file in sorted(docstructure_files):
            print(f"  - {file}")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ JSON —Ñ–∞–π–ª–æ–≤
        json_tables = set()
        json_fields = set()
        
        for file in docstructure_files:
            if file.endswith('.json'):
                file_path = os.path.join(docstructure_dir, file)
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã –∏ –ø–æ–ª—è
                    if isinstance(data, dict):
                        for key, value in data.items():
                            if isinstance(value, dict):
                                if 'table' in key.lower() or 'table' in str(value).lower():
                                    json_tables.add(key)
                                if 'field' in key.lower() or 'field' in str(value).lower():
                                    json_fields.add(key)
                    
                    # –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü –≤ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º
                    content = str(data).lower()
                    if 'tbl_' in content:
                        # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π —Ç–∞–±–ª–∏—Ü
                        import re
                        table_matches = re.findall(r'tbl_\w+', content)
                        json_tables.update(table_matches)
                
                except Exception as e:
                    print(f"  ‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {file}: {e}")
        
        print(f"\nüìä –ê–Ω–∞–ª–∏–∑ DocStructureSchema:")
        print(f"  –ù–∞–π–¥–µ–Ω–æ —Ç–∞–±–ª–∏—Ü: {len(json_tables)}")
        print(f"  –ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ–π: {len(json_fields)}")
        
        if json_tables:
            print(f"  –¢–∞–±–ª–∏—Ü—ã –≤ DocStructureSchema:")
            for table in sorted(json_tables):
                print(f"    - {table}")
        
        return {
            'files': docstructure_files,
            'tables': list(json_tables),
            'fields': list(json_fields)
        }
    
    async def audit_qa_coverage(self):
        """–ê—É–¥–∏—Ç –ø–æ–∫—Ä—ã—Ç–∏—è Q/A –ø–∞—Ä"""
        print("\nüîç –ê—É–¥–∏—Ç –ø–æ–∫—Ä—ã—Ç–∏—è Q/A –ø–∞—Ä...")
        
        conn = await asyncpg.connect(self.database_url)
        
        # –ê–Ω–∞–ª–∏–∑ Q/A –ø–∞—Ä
        qa_stats = await conn.fetch("""
            SELECT 
                COUNT(*) as total_qa,
                COUNT(CASE WHEN content ILIKE '%payment%' THEN 1 END) as payment_qa,
                COUNT(CASE WHEN content ILIKE '%tbl_%' THEN 1 END) as table_qa,
                COUNT(CASE WHEN content ILIKE '%SELECT%' THEN 1 END) as sql_qa
            FROM vanna_vectors 
            WHERE content_type = 'question_sql'
        """)
        
        if qa_stats:
            stat = qa_stats[0]
            print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ Q/A –ø–∞—Ä:")
            print(f"  –í—Å–µ–≥–æ Q/A: {stat['total_qa']}")
            print(f"  –° —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º 'payment': {stat['payment_qa']}")
            print(f"  –° —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º 'tbl_': {stat['table_qa']}")
            print(f"  –° SQL –∑–∞–ø—Ä–æ—Å–∞–º–∏: {stat['sql_qa']}")
        
        # –ü—Ä–∏–º–µ—Ä—ã Q/A –ø–∞—Ä
        sample_qa = await conn.fetch("""
            SELECT content 
            FROM vanna_vectors 
            WHERE content_type = 'question_sql'
            ORDER BY id
            LIMIT 3
        """)
        
        print(f"\nüìù –ü—Ä–∏–º–µ—Ä—ã Q/A –ø–∞—Ä:")
        for i, qa in enumerate(sample_qa, 1):
            content = qa['content']
            preview = content[:200] + "..." if len(content) > 200 else content
            print(f"  {i}. {preview}")
        
        await conn.close()
        
        return dict(qa_stats[0]) if qa_stats else {}
    
    async def audit_documentation_coverage(self):
        """–ê—É–¥–∏—Ç –ø–æ–∫—Ä—ã—Ç–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
        print("\nüîç –ê—É–¥–∏—Ç –ø–æ–∫—Ä—ã—Ç–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏...")
        
        conn = await asyncpg.connect(self.database_url)
        
        # –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
        doc_stats = await conn.fetch("""
            SELECT 
                COUNT(*) as total_docs,
                COUNT(CASE WHEN content ILIKE '%payment%' THEN 1 END) as payment_docs,
                COUNT(CASE WHEN content ILIKE '%tbl_%' THEN 1 END) as table_docs,
                COUNT(CASE WHEN content ILIKE '%CREATE TABLE%' THEN 1 END) as ddl_docs
            FROM vanna_vectors 
            WHERE content_type = 'documentation'
        """)
        
        if doc_stats:
            stat = doc_stats[0]
            print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:")
            print(f"  –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {stat['total_docs']}")
            print(f"  –° —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º 'payment': {stat['payment_docs']}")
            print(f"  –° —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º 'tbl_': {stat['table_docs']}")
            print(f"  –° DDL: {stat['ddl_docs']}")
        
        # –ü—Ä–∏–º–µ—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
        sample_docs = await conn.fetch("""
            SELECT content 
            FROM vanna_vectors 
            WHERE content_type = 'documentation'
            AND content ILIKE '%payment%'
            ORDER BY id
            LIMIT 3
        """)
        
        print(f"\nüìù –ü—Ä–∏–º–µ—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–æ –ø–ª–∞—Ç–µ–∂–∞–º:")
        for i, doc in enumerate(sample_docs, 1):
            content = doc['content']
            preview = content[:200] + "..." if len(content) > 200 else content
            print(f"  {i}. {preview}")
        
        await conn.close()
        
        return dict(doc_stats[0]) if doc_stats else {}
    
    async def generate_coverage_report(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –ø–æ–∫—Ä—ã—Ç–∏–∏"""
        print("\nüìã –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –ø–æ–∫—Ä—ã—Ç–∏–∏...")
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
        vector_stats = await self.audit_vector_db_coverage()
        docstructure_stats = await self.audit_docstructure_schema()
        qa_stats = await self.audit_qa_coverage()
        doc_stats = await self.audit_documentation_coverage()
        
        # –ê–Ω–∞–ª–∏–∑ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏
        print("\nüéØ –ê–Ω–∞–ª–∏–∑ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏ –∑–Ω–∞–Ω–∏–π:")
        
        # 1. –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ DocStructureSchema?
        docstructure_tables = set(docstructure_stats['tables'])
        db_tables = set(vector_stats['missing_tables'] + [t for t in vector_stats['payment_tables'] if t in vector_stats['missing_tables']])
        
        docstructure_coverage = len(docstructure_tables & db_tables) / len(db_tables) if db_tables else 0
        
        print(f"  üìÅ DocStructureSchema –ø–æ–∫—Ä—ã—Ç–∏–µ: {docstructure_coverage:.1%}")
        if docstructure_coverage < 0.5:
            print("    ‚ùå DocStructureSchema –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ - –Ω—É–∂–Ω—ã DDL –∏–∑ –ë–î")
        else:
            print("    ‚úÖ DocStructureSchema –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ")
        
        # 2. –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ Q/A –ø–∞—Ä?
        qa_coverage = qa_stats.get('payment_qa', 0) / max(qa_stats.get('total_qa', 1), 1)
        print(f"  ‚ùì Q/A –ø–æ–∫—Ä—ã—Ç–∏–µ –ø–ª–∞—Ç–µ–∂–µ–π: {qa_coverage:.1%}")
        if qa_coverage < 0.1:
            print("    ‚ùå Q/A –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ - –Ω—É–∂–Ω—ã –ø—Ä–∏–º–µ—Ä—ã –ø–æ –ø–ª–∞—Ç–µ–∂–∞–º")
        else:
            print("    ‚úÖ Q/A –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ")
        
        # 3. –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏?
        doc_coverage = doc_stats.get('payment_docs', 0) / max(doc_stats.get('total_docs', 1), 1)
        print(f"  üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ –ø–ª–∞—Ç–µ–∂–∞–º: {doc_coverage:.1%}")
        if doc_coverage < 0.1:
            print("    ‚ùå –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ")
        else:
            print("    ‚úÖ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        print(f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        
        if docstructure_coverage < 0.5:
            print("  1. üîß –î–æ–±–∞–≤–∏—Ç—å DDL –∏–∑ –∂–∏–≤–æ–π –ë–î –¥–ª—è –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —Ç–∞–±–ª–∏—Ü")
        
        if qa_coverage < 0.1:
            print("  2. üìù –î–æ–±–∞–≤–∏—Ç—å Q/A –ø—Ä–∏–º–µ—Ä—ã –ø–æ –ø–ª–∞—Ç–µ–∂–∞–º")
        
        if doc_coverage < 0.1:
            print("  3. üìö –†–∞—Å—à–∏—Ä–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –ø–æ –ø–ª–∞—Ç–µ–∂–∞–º")
        
        if vector_stats['payment_missing']:
            print(f"  4. üéØ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –¥–æ–±–∞–≤–∏—Ç—å DDL –¥–ª—è {vector_stats['payment_missing']}")
        
        return {
            'vector_stats': vector_stats,
            'docstructure_stats': docstructure_stats,
            'qa_stats': qa_stats,
            'doc_stats': doc_stats,
            'recommendations': {
                'docstructure_sufficient': docstructure_coverage >= 0.5,
                'qa_sufficient': qa_coverage >= 0.1,
                'doc_sufficient': doc_coverage >= 0.1
            }
        }

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞—É–¥–∏—Ç–∞"""
    auditor = KnowledgeCoverageAuditor()
    
    print("üöÄ –ó–∞–ø—É—Å–∫ –∞—É–¥–∏—Ç–∞ –ø–æ–∫—Ä—ã—Ç–∏—è –∑–Ω–∞–Ω–∏–π...")
    
    report = await auditor.generate_coverage_report()
    
    print("\n‚úÖ –ê—É–¥–∏—Ç –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print(f"üìä –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –ø–∞–º—è—Ç–∏, –≥–æ—Ç–æ–≤ –∫ –∞–Ω–∞–ª–∏–∑—É")

if __name__ == "__main__":
    asyncio.run(main())
