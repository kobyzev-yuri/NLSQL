#!/usr/bin/env python3
"""
Vanna AI —Å –Ω–∞—Å—Ç–æ—è—â–∏–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º –ø–æ–∏—Å–∫–æ–º —á–µ—Ä–µ–∑ pgvector
"""

import os
import logging
import asyncio
import asyncpg
from typing import List, Dict, Any, Optional
from openai import OpenAI

logger = logging.getLogger(__name__)

class SemanticRAG:
    """RAG —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º –ø–æ–∏—Å–∫–æ–º —á–µ—Ä–µ–∑ pgvector"""
    
    def __init__(self, dsn: str, api_key: str, base_url: str = None):
        self.dsn = dsn
        self.client = OpenAI(
            api_key=api_key,
            base_url=base_url or "https://api.proxyapi.ru/openai/v1"
        )
    
    async def get_semantic_context(self, question: str, limit: int = 3) -> Dict[str, List[str]]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        
        Args:
            question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –ø–æ —Ç–∏–ø—É
            
        Returns:
            Dict —Å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –ø–æ —Ç–∏–ø–∞–º
        """
        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞
            question_embedding = await self._generate_embedding(question)
            
            # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î
            conn = await asyncpg.connect(self.dsn)
            
            # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
            docs = await self._semantic_search(conn, question_embedding, 'documentation', limit)
            
            # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ Q/A –ø–∞—Ä–∞–º
            qa_pairs = await self._semantic_search(conn, question_embedding, 'question_sql', limit)
            
            # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ DDL
            ddl = await self._semantic_search(conn, question_embedding, 'ddl', limit)
            
            await conn.close()
            
            return {
                'documentation': docs,
                'question_sql': qa_pairs,
                'ddl': ddl
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}")
            return {'documentation': [], 'question_sql': [], 'ddl': []}
    
    async def _generate_embedding(self, text: str) -> List[float]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
        try:
            from sentence_transformers import SentenceTransformer
            model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
            return model.encode(text, convert_to_tensor=True).tolist()
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            return []
    
    async def _semantic_search(self, conn: asyncpg.Connection, query_embedding: List[float], 
                              content_type: str, limit: int) -> List[str]:
        """–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ —Ç–∏–ø—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –≤ —Å—Ç—Ä–æ–∫—É –¥–ª—è pgvector
            embedding_str = '[' + ','.join(map(str, query_embedding)) + ']'
            
            # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º cosine distance
            query = """
                SELECT content, embedding <-> $1::vector as distance
                FROM vanna_vectors 
                WHERE content_type = $2 AND embedding IS NOT NULL
                ORDER BY embedding <-> $1::vector
                LIMIT $3
            """
            
            results = await conn.fetch(query, embedding_str, content_type, limit)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –∫–æ–Ω—Ç–µ–Ω—Ç, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
            content = [row['content'] for row in results]
            
            logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(content)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö {content_type} –∑–∞–ø–∏—Å–µ–π")
            return content
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ {content_type}: {e}")
            return []

async def test_semantic_search():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
    dsn = "postgresql://postgres:1234@localhost:5432/test_docstructure"
    api_key = os.getenv("PROXYAPI_KEY")
    
    if not api_key:
        logger.error("‚ùå PROXYAPI_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    rag = SemanticRAG(dsn, api_key)
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã
    test_questions = [
        "–ü–æ–∫–∞–∂–∏ –ø–æ—Ä—É—á–µ–Ω–∏—è –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü",
        "–°–ø–∏—Å–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ –æ—Ç–¥–µ–ª–∞–º", 
        "–ü–ª–∞—Ç–µ–∂–∏ –ø–æ –∫–ª–∏–µ–Ω—Ç–∞–º",
        "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"
    ]
    
    for question in test_questions:
        print(f"\nüîç –í–æ–ø—Ä–æ—Å: {question}")
        context = await rag.get_semantic_context(question, limit=2)
        
        for content_type, items in context.items():
            if items:
                print(f"  üìã {content_type}: {len(items)} –∑–∞–ø–∏—Å–µ–π")
                for i, item in enumerate(items[:1]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é
                    preview = item[:100] + "..." if len(item) > 100 else item
                    print(f"    {i+1}. {preview}")

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    asyncio.run(test_semantic_search())

