#!/usr/bin/env python3
"""
–î–≤—É—Ö–º–æ–¥–µ–ª—å–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è NL‚ÜíSQL –∞–≥–µ–Ω—Ç–∞
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç GPT-4o –∏ Ollama Llama 3 —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ–º
"""

import os
import logging
import time
from typing import Optional, Dict, Any, List
from pathlib import Path
import sys

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(str(Path(__file__).parent.parent))

from src.vanna.vanna_pgvector_native import DocStructureVannaNative

logger = logging.getLogger(__name__)

class DualModelPipeline:
    """
    –î–≤—É—Ö–º–æ–¥–µ–ª—å–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è NL‚ÜíSQL –∞–≥–µ–Ω—Ç–∞
    –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å: GPT-4o, –†–µ–∑–µ—Ä–≤–Ω–∞—è: Ollama Llama 3
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–≤—É—Ö–º–æ–¥–µ–ª—å–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞
        
        Args:
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –æ–±–µ–∏—Ö –º–æ–¥–µ–ª–µ–π
        """
        if config is None:
            config = {}
            
        self.config = config
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è GPT-4o (–æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å)
        self.gpt4_config = {
            'model': 'gpt-4o',
            'database_url': 'postgresql://postgres:1234@localhost:5432/test_docstructure',
            'api_key': 'sk-xF20r7G4tq9ezBMNKIjCPvva2io4S8FV',
            'base_url': 'https://api.proxyapi.ru/openai/v1',
            'temperature': 0.2
        }
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è Ollama Llama 3 (—Ä–µ–∑–µ—Ä–≤–Ω–∞—è –º–æ–¥–µ–ª—å)
        self.ollama_config = {
            'model': 'llama3:latest',
            'database_url': 'postgresql://postgres:1234@localhost:5432/test_docstructure',
            'api_key': 'ollama',
            'base_url': 'http://localhost:11434/v1',
            'temperature': 0.2
        }
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
        self.gpt4_config.update(config.get('gpt4', {}))
        self.ollama_config.update(config.get('ollama', {}))
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–≥–µ–Ω—Ç–æ–≤
        self.gpt4_agent = None
        self.ollama_agent = None
        self.current_model = None
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        self.usage_stats = {
            'gpt4': {'calls': 0, 'success': 0, 'errors': 0, 'total_time': 0},
            'ollama': {'calls': 0, 'success': 0, 'errors': 0, 'total_time': 0}
        }
        
        logger.info("‚úÖ DualModelPipeline –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def _init_gpt4_agent(self) -> bool:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GPT-4o –∞–≥–µ–Ω—Ç–∞"""
        try:
            if self.gpt4_agent is None:
                self.gpt4_agent = DocStructureVannaNative(self.gpt4_config)
                logger.info("‚úÖ GPT-4o –∞–≥–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ GPT-4o: {e}")
            return False
    
    def _init_ollama_agent(self) -> bool:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Ollama –∞–≥–µ–Ω—Ç–∞"""
        try:
            if self.ollama_agent is None:
                self.ollama_agent = DocStructureVannaNative(self.ollama_config)
                logger.info("‚úÖ Ollama –∞–≥–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Ollama: {e}")
            return False
    
    def generate_sql(self, question: str, prefer_model: str = 'auto', timeout: int = 30) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è SQL —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –≤—ã–±–æ—Ä–æ–º –º–æ–¥–µ–ª–∏
        
        Args:
            question: –í–æ–ø—Ä–æ—Å –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ
            prefer_model: –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º–∞—è –º–æ–¥–µ–ª—å ('gpt4', 'ollama', 'auto')
            timeout: –¢–∞–π–º–∞—É—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        """
        start_time = time.time()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –º–æ–¥–µ–ª–µ–π
        if prefer_model == 'gpt4':
            models_order = ['gpt4', 'ollama']
        elif prefer_model == 'ollama':
            models_order = ['ollama', 'gpt4']
        else:  # auto
            models_order = ['gpt4', 'ollama']  # GPT-4o –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        for model_name in models_order:
            try:
                logger.info(f"üîÑ –ü–æ–ø—ã—Ç–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SQL —Å {model_name}...")
                
                if model_name == 'gpt4':
                    if not self._init_gpt4_agent():
                        continue
                    agent = self.gpt4_agent
                else:
                    if not self._init_ollama_agent():
                        continue
                    agent = self.ollama_agent
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º SQL
                model_start = time.time()
                sql = agent.generate_sql(question)
                model_end = time.time()
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                self.usage_stats[model_name]['calls'] += 1
                self.usage_stats[model_name]['success'] += 1
                self.usage_stats[model_name]['total_time'] += (model_end - model_start)
                
                self.current_model = model_name
                total_time = time.time() - start_time
                
                result = {
                    'success': True,
                    'sql': sql,
                    'model': model_name,
                    'time': total_time,
                    'model_time': model_end - model_start,
                    'question': question
                }
                
                logger.info(f"‚úÖ SQL —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω —Å {model_name} –∑–∞ {total_time:.2f} —Å–µ–∫")
                return result
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å {model_name}: {e}")
                self.usage_stats[model_name]['errors'] += 1
                continue
        
        # –ï—Å–ª–∏ –≤—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏
        total_time = time.time() - start_time
        return {
            'success': False,
            'error': '–í—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã',
            'time': total_time,
            'question': question
        }
    
    def train_on_schema(self) -> bool:
        """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ —Å—Ö–µ–º–µ –ë–î –¥–ª—è –æ–±–µ–∏—Ö –º–æ–¥–µ–ª–µ–π"""
        success_count = 0
        
        # –û–±—É—á–∞–µ–º GPT-4o
        if self._init_gpt4_agent():
            try:
                logger.info("üìö –û–±—É—á–µ–Ω–∏–µ GPT-4o –Ω–∞ —Å—Ö–µ–º–µ –ë–î...")
                schema_query = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS"
                df_schema = self.gpt4_agent.run_sql(schema_query)
                plan = self.gpt4_agent.get_training_plan_generic(df_schema)
                self.gpt4_agent.train(plan=plan)
                logger.info("‚úÖ GPT-4o –æ–±—É—á–µ–Ω –Ω–∞ —Å—Ö–µ–º–µ")
                success_count += 1
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è GPT-4o: {e}")
        
        # –û–±—É—á–∞–µ–º Ollama
        if self._init_ollama_agent():
            try:
                logger.info("üìö –û–±—É—á–µ–Ω–∏–µ Ollama –Ω–∞ —Å—Ö–µ–º–µ –ë–î...")
                schema_query = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS"
                df_schema = self.ollama_agent.run_sql(schema_query)
                plan = self.ollama_agent.get_training_plan_generic(df_schema)
                self.ollama_agent.train(plan=plan)
                logger.info("‚úÖ Ollama –æ–±—É—á–µ–Ω –Ω–∞ —Å—Ö–µ–º–µ")
                success_count += 1
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è Ollama: {e}")
        
        return success_count > 0
    
    def train_on_examples(self, examples: List[Dict[str, str]]) -> bool:
        """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö –¥–ª—è –æ–±–µ–∏—Ö –º–æ–¥–µ–ª–µ–π"""
        success_count = 0
        
        for example in examples:
            question = example.get('question', '')
            sql = example.get('sql', '')
            
            if not question or not sql:
                continue
            
            # –û–±—É—á–∞–µ–º GPT-4o
            if self._init_gpt4_agent():
                try:
                    self.gpt4_agent.train(question=question, sql=sql)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è GPT-4o –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ: {e}")
            
            # –û–±—É—á–∞–µ–º Ollama
            if self._init_ollama_agent():
                try:
                    self.ollama_agent.train(question=question, sql=sql)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è Ollama –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ: {e}")
        
        logger.info(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –Ω–∞ {len(examples)} –ø—Ä–∏–º–µ—Ä–∞—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        return True
    
    def get_usage_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        stats = {}
        
        for model_name, model_stats in self.usage_stats.items():
            if model_stats['calls'] > 0:
                stats[model_name] = {
                    'calls': model_stats['calls'],
                    'success_rate': model_stats['success'] / model_stats['calls'],
                    'error_rate': model_stats['errors'] / model_stats['calls'],
                    'avg_time': model_stats['total_time'] / model_stats['success'] if model_stats['success'] > 0 else 0
                }
            else:
                stats[model_name] = {
                    'calls': 0,
                    'success_rate': 0,
                    'error_rate': 0,
                    'avg_time': 0
                }
        
        return stats
    
    def health_check(self) -> Dict[str, bool]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –æ–±–µ–∏—Ö –º–æ–¥–µ–ª–µ–π"""
        health = {}
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º GPT-4o
        try:
            if self._init_gpt4_agent():
                # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç
                test_result = self.gpt4_agent.generate_sql("SELECT 1")
                health['gpt4'] = True
            else:
                health['gpt4'] = False
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è GPT-4o –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
            health['gpt4'] = False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Ollama
        try:
            if self._init_ollama_agent():
                # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç
                test_result = self.ollama_agent.generate_sql("SELECT 1")
                health['ollama'] = True
            else:
                health['ollama'] = False
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
            health['ollama'] = False
        
        return health

def create_dual_model_pipeline(config: Optional[Dict[str, Any]] = None) -> DualModelPipeline:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –¥–≤—É—Ö–º–æ–¥–µ–ª—å–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞
    
    Args:
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        
    Returns:
        DualModelPipeline: –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω
    """
    return DualModelPipeline(config)

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞
    pipeline = DualModelPipeline()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è
    health = pipeline.health_check()
    print(f"–ó–¥–æ—Ä–æ–≤—å–µ –º–æ–¥–µ–ª–µ–π: {health}")
    
    # –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    result = pipeline.generate_sql("–ü–æ–∫–∞–∂–∏ –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = pipeline.get_usage_stats()
    print(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats}")
