"""
–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∑–∞–ø—Ä–æ—Å–∞–º–∏ –∏ Vanna AI
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

import logging
from typing import Dict, Any, Optional
from src.vanna.optimized_dual_pipeline import OptimizedDualPipeline
from src.vanna.vanna_semantic_fixed import create_semantic_vanna_client

logger = logging.getLogger(__name__)


class QueryService:
    """
    –°–µ—Ä–≤–∏—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SQL
    """
    
    def __init__(self):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞
        """
        self.pipeline = None
        self.semantic_vanna = None
        self._initialize_pipeline()
        self._initialize_semantic_rag()
    
    def _initialize_pipeline(self):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞
        """
        try:
            # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ (–∫–ª—é—á–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç OptimizedDualPipeline)
            config = {
                'gpt4': {
                    'model': 'gpt-4o',
                    'database_url': 'postgresql://postgres:1234@localhost:5432/test_docstructure',
                    'api_key': os.getenv("PROXYAPI_KEY") or os.getenv("PROXYAPI_API_KEY") or os.getenv("OPENAI_API_KEY"),
                    'base_url': 'https://api.proxyapi.ru/openai/v1',
                    'temperature': 0.2
                },
                'ollama': {
                    'model': 'llama3:latest',
                    'database_url': 'postgresql://postgres:1234@localhost:5432/test_docstructure',
                    'api_key': 'ollama',
                    'base_url': 'http://localhost:11434/v1',
                    'temperature': 0.2
                },
                'training_data_path': 'training_data/enhanced_sql_examples.json'
            }
            
            self.pipeline = OptimizedDualPipeline(config)
            # –§–ª–∞–≥ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –≤–Ω–µ—à–Ω–µ–≥–æ API –¥–ª—è –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            self._has_gpt4_key = bool(config['gpt4']['api_key'])
            logger.info("–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–∞–π–ø–ª–∞–π–Ω–∞: {e}")
            raise
    
    def _initialize_semantic_rag(self):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ RAG
        """
        try:
            self.semantic_vanna = create_semantic_vanna_client()
            logger.info("‚úÖ –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π RAG –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ RAG: {e}")
            self.semantic_vanna = None
    
    def _detect_domain(self, question: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –¥–æ–º–µ–Ω –∑–∞–ø—Ä–æ—Å–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º."""
        question_lower = question.lower()
        
        # –î–æ–º–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        domain_configs = {
            'payments': {
                'keywords': ['–ø–ª–∞—Ç–µ–∂', 'payment', '–æ–ø–ª–∞—Ç–∞', '–¥–µ–Ω—å–≥–∏', '–¥–µ–Ω–µ–≥', '—Å—É–º–º–∞', '—Ä—É–±–ª—å', '—Ä—É–±–ª–µ–π', '–≤—Ö–æ–¥—è—â–∏–π', '–∏—Å—Ö–æ–¥—è—â–∏–π'],
                'tables': ['tbl_incoming_payments', 'tbl_payment_statuses', 'tbl_postpayment_types', 'tbl_business_unit', 'tbl_principal_assignment']
            },
            'users': {
                'keywords': ['–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å', 'user', '—Å–æ—Ç—Ä—É–¥–Ω–∏–∫', '–º–µ–Ω–µ–¥–∂–µ—Ä', '–∞–¥–º–∏–Ω', '–ª–æ–≥–∏–Ω', '–æ—Ç–¥–µ–ª', '–¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç'],
                'tables': ['equsers', 'eq_departments', 'eqroles', 'eqgroups']
            },
            'assignments': {
                'keywords': ['–ø–æ—Ä—É—á–µ–Ω–∏–µ', '–ø–æ—Ä—É—á–µ–Ω–∏—è', 'assignment', 'assignments', '–∑–∞–¥–∞–Ω–∏–µ', '–∑–∞–¥–∞–Ω–∏—è', '–¥–æ–∫—É–º–µ–Ω—Ç', '–¥–æ–∫—É–º–µ–Ω—Ç—ã', '–¥–æ–≥–æ–≤–æ—Ä', '–∫–æ–Ω—Ç—Ä–∞–∫—Ç', 'task', 'tasks'],
                'tables': ['tbl_principal_assignment', 'tbl_business_unit', 'equsers']
            },
            'reports': {
                'keywords': ['–æ—Ç—á–µ—Ç', 'report', '—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', '–∞–Ω–∞–ª–∏—Ç–∏–∫–∞', '—Å–≤–æ–¥–∫–∞', '–∏—Ç–æ–≥'],
                'tables': ['tbl_incoming_payments', 'equsers', 'eq_departments', 'tbl_business_unit']
            }
        }
        
        # –ü–æ–¥—Å—á–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ –¥–æ–º–µ–Ω–∞–º
        domain_scores = {}
        for domain, config in domain_configs.items():
            score = sum(1 for keyword in config['keywords'] if keyword in question_lower)
            if score > 0:
                domain_scores[domain] = score
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–æ–º–µ–Ω —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º —Å—á–µ—Ç–æ–º –∏–ª–∏ 'general'
        if domain_scores:
            return max(domain_scores, key=domain_scores.get)
        return 'general'

    async def _get_tables_ddl(self, table_names: list[str]) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–π DDL –¥–ª—è –∑–∞–¥–∞–Ω–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü –∏–∑ vanna_vectors (content_type='ddl')."""
        try:
            import asyncpg
            conn = await asyncpg.connect("postgresql://postgres:1234@localhost:5432/test_docstructure")
            rows = await conn.fetch(
                """
                SELECT metadata, content
                FROM vanna_vectors
                WHERE content_type='ddl' AND (metadata->>'table') = ANY($1)
                ORDER BY id
                """,
                table_names,
            )
            await conn.close()
            parts: list[str] = []
            for r in rows:
                md = r["metadata"]
                if isinstance(md, str):
                    import json
                    try:
                        md = json.loads(md)
                    except:
                        md = {}
                t = (md or {}).get("table", "unknown")
                ddl = r["content"] or ""
                # –£—Å–µ—á–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Ç–µ–ª–∞, –æ—Å—Ç–∞–≤–∏–º –ø–µ—Ä–≤—ã–µ ~60 —Å—Ç—Ä–æ–∫
                head = "\n".join(ddl.splitlines()[:60])
                parts.append(f"TABLE: public.{t}\n{head}")
            return "\n\n".join(parts)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è DDL —Ç–∞–±–ª–∏—Ü: {e}")
            return ""

    async def _get_rag_context(self, question: str, domain: str) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –¥–æ–º–µ–Ω–∞."""
        try:
            # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —Å –¥–æ–º–µ–Ω–Ω—ã–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
            if self.semantic_vanna:
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º top_k –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è
                results = await self.semantic_vanna.get_similar_question_sql(question, top_k=10)
                if results:
                    context_parts = []
                    for result in results[:5]:  # –ë–µ—Ä–µ–º —Ç–æ–ø-5
                        # –†–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ "Q: ... A: ..."
                        if isinstance(result, str):
                            context_parts.append(result)
                        elif hasattr(result, 'question') and hasattr(result, 'sql'):
                            context_parts.append(f"Q: {result.question}\nSQL: {result.sql}")
                    return "\n\n".join(context_parts)
            return ""
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}")
            return ""

    def _build_smart_prompt(self, question: str, domain: str, ddl_tables: str, rag_context: str) -> str:
        """–°—Ç—Ä–æ–∏—Ç —É–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –¥–æ–º–µ–Ω–Ω–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–µ–π."""
        if domain == 'general':
            # –î–ª—è –æ–±—â–µ–≥–æ –¥–æ–º–µ–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥
            return question
        
        # –î–æ–º–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        prompt_parts = [
            f"===Domain: {domain.upper()}",
            f"===Tables (Domain-specific DDL)",
            ddl_tables,
        ]
        
        if rag_context:
            prompt_parts.extend([
                f"===Additional Context (RAG)",
                rag_context,
            ])
        
        prompt_parts.extend([
            f"===Question (ru)",
            question
        ])
        
        return "\n\n".join(prompt_parts)

    async def _retrieve_payment_context(self, question: str) -> str:
        """–ì–∏–±—Ä–∏–¥–Ω—ã–π —Ä–µ—Ç—Ä–∏–≤–µ—Ä –¥–ª—è –ø–ª–∞—Ç–µ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ —Å BM25 + —Å–µ–º–∞–Ω—Ç–∏–∫–æ–π"""
        try:
            import asyncpg
            import re
            from openai import OpenAI
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –≤–æ–ø—Ä–æ—Å –ø–ª–∞—Ç–µ–∂–Ω—É—é —Ç–µ–º–∞—Ç–∏–∫—É
            payment_keywords = ['–ø–ª–∞—Ç–µ–∂', 'payment', '–ø–ª–∞—Ç–µ–∂–∏', 'payments', '–≤—Ö–æ–¥—è—â–∏–µ', 'incoming', '—Å—Ç–∞—Ç—É—Å', 'status']
            is_payment_query = any(keyword in question.lower() for keyword in payment_keywords)
            
            if not is_payment_query:
                return ""
            
            # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î
            conn = await asyncpg.connect("postgresql://postgres:1234@localhost:5432/test_docstructure")
            
            # BM25 –ø–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
            bm25_results = await conn.fetch("""
                SELECT content, content_type, metadata
                FROM vanna_vectors 
                WHERE content_type = 'ddl' 
                AND (
                    content ILIKE '%tbl_incoming_payments%' OR
                    content ILIKE '%tbl_payment_statuses%' OR
                    content ILIKE '%tbl_postpayment_types%' OR
                    content ILIKE '%tbl_business_unit%' OR
                    content ILIKE '%tbl_principal_assignment%'
                )
                ORDER BY 
                    CASE 
                        WHEN content ILIKE '%tbl_incoming_payments%' THEN 1
                        WHEN content ILIKE '%tbl_payment_statuses%' THEN 2
                        WHEN content ILIKE '%tbl_postpayment_types%' THEN 3
                        WHEN content ILIKE '%tbl_business_unit%' THEN 4
                        WHEN content ILIKE '%tbl_principal_assignment%' THEN 5
                        ELSE 6
                    END
                LIMIT 10
            """)
            
            # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —Å HF –º–æ–¥–µ–ª—å—é (384 —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å)
            from sentence_transformers import SentenceTransformer
            model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
            question_embedding = model.encode(question, convert_to_tensor=True).tolist()
            embedding_str = '[' + ','.join(map(str, question_embedding)) + ']'
            
            semantic_results = await conn.fetch("""
                SELECT content, content_type, metadata, embedding <-> $1::vector as distance
                FROM vanna_vectors 
                WHERE content_type = 'ddl' 
                AND embedding IS NOT NULL
                AND (
                    content ILIKE '%tbl_incoming_payments%' OR
                    content ILIKE '%tbl_payment_statuses%' OR
                    content ILIKE '%tbl_postpayment_types%' OR
                    content ILIKE '%tbl_business_unit%' OR
                    content ILIKE '%tbl_principal_assignment%'
                )
                ORDER BY embedding <-> $1::vector
                LIMIT 15
            """, embedding_str)
            
            await conn.close()
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            all_results = list(bm25_results) + list(semantic_results)
            seen_content = set()
            unique_results = []
            
            for result in all_results:
                if result['content'] not in seen_content:
                    unique_results.append(result)
                    seen_content.add(result['content'])
                    if len(unique_results) >= 8:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
                        break
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
            context_parts = []
            for result in unique_results:
                # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø–∞—Ä—Å–∏–Ω–≥ metadata
                metadata = result['metadata']
                if isinstance(metadata, str):
                    import json
                    try:
                        metadata = json.loads(metadata)
                    except:
                        metadata = {}
                table_name = metadata.get('table', 'unknown') if metadata else 'unknown'
                context_parts.append(f"–¢–∞–±–ª–∏—Ü–∞ {table_name}:\n{result['content'][:500]}...")
            
            return "\n\n".join(context_parts)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞: {e}")
            return ""

    async def generate_sql(self, question: str, user_context: Dict[str, Any]) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è SQL –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–æ–ø—Ä–æ—Å–∞ —Å —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–º –¥–æ–º–µ–Ω–Ω—ã–º –ø–æ–¥—Ö–æ–¥–æ–º
        
        Args:
            question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            str: SQL –∑–∞–ø—Ä–æ—Å
        """
        try:
            logger.info(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è SQL –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞: {question}")

            # –®–∞–≥ 1: –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ–º–µ–Ω –∑–∞–ø—Ä–æ—Å–∞
            domain = self._detect_domain(question)
            logger.info(f"üéØ –û–ø—Ä–µ–¥–µ–ª–µ–Ω –¥–æ–º–µ–Ω: {domain}")

            # –®–∞–≥ 2: –ü–æ–ª—É—á–∞–µ–º –¥–æ–º–µ–Ω–Ω—ã–µ DDL —Ç–∞–±–ª–∏—Ü—ã
            domain_configs = {
                'payments': ['tbl_incoming_payments', 'tbl_payment_statuses', 'tbl_postpayment_types', 'tbl_business_unit', 'tbl_principal_assignment'],
                'users': ['equsers', 'eq_departments', 'eqroles', 'eqgroups'],
                'assignments': ['tbl_principal_assignment', 'tbl_business_unit', 'equsers'],
                'reports': ['tbl_incoming_payments', 'equsers', 'eq_departments', 'tbl_business_unit']
            }
            
            ddl_tables = ""
            if domain in domain_configs:
                ddl_tables = await self._get_tables_ddl(domain_configs[domain])
                logger.info(f"üìã –ü–æ–ª—É—á–µ–Ω DDL –¥–ª—è –¥–æ–º–µ–Ω–∞ {domain}: {len(ddl_tables)} —Å–∏–º–≤–æ–ª–æ–≤")

            # –®–∞–≥ 3: –ü–æ–ª—É—á–∞–µ–º RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç
            rag_context = await self._get_rag_context(question, domain)
            if rag_context:
                logger.info(f"üîç –ü–æ–ª—É—á–µ–Ω RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç: {len(rag_context)} —Å–∏–º–≤–æ–ª–æ–≤")

            # –®–∞–≥ 4: –°—Ç—Ä–æ–∏–º —É–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            smart_question = self._build_smart_prompt(question, domain, ddl_tables, rag_context)
            logger.info(f"üß† –ü–æ—Å—Ç—Ä–æ–µ–Ω —É–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –¥–æ–º–µ–Ω–∞ {domain}")

            # –®–∞–≥ 5: –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º SQL —á–µ—Ä–µ–∑ –ø–∞–π–ø–ª–∞–π–Ω
            logger.info("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –ø–∞–π–ø–ª–∞–π–Ω —Å GPT-4o...")
            prefer_primary = 'openai'  # –ò—Å–ø–æ–ª—å–∑—É–µ–º GPT-4o
            result = self.pipeline.generate_sql(smart_question, prefer_model=prefer_primary)

            # –ï—Å–ª–∏ –Ω–µ—É—Å–ø–µ—Ö –∏–∑-–∑–∞ –∫–ª—é—á–∞/401 ‚Äî —Ñ–æ–ª–ª–±—ç–∫ –Ω–∞ ollama
            def need_fallback(res, err: Optional[Exception] = None) -> bool:
                text = ''
                if isinstance(res, dict):
                    text = f"{res.get('error', '')} {res.get('message', '')}"
                if err:
                    text += f" {str(err)}"
                text = text.lower()
                return '401' in text or 'invalid api key' in text or 'unauthorized' in text

            if not (result and result.get('success') and result.get('sql')) and (prefer_primary != 'ollama') and need_fallback(result):
                logger.warning("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ GPT-4 –Ω–µ —É–¥–∞–ª–∞—Å—å (–∫–ª—é—á/401). –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ ollama.")
                result = self.pipeline.generate_sql(question, prefer_model='ollama')

            if result and result.get('success') and result.get('sql'):
                sql = result['sql']
                logger.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω SQL —Å –ø–æ–º–æ—â—å—é {result.get('model', 'unknown')}: {sql}")
                return sql

            error_msg = result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞') if isinstance(result, dict) else str(result)
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SQL: {error_msg}")
            raise Exception(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SQL: {error_msg}")

        except Exception as e:
            # –§–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–æ–ª–ª–±—ç–∫: –ø—Ä–æ–±—É–µ–º ollama –æ–¥–∏–Ω —Ä–∞–∑, –µ—Å–ª–∏ —Ä–∞–Ω–µ–µ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∏
            try:
                logger.warning(f"–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ ollama –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏: {e}")
                result = self.pipeline.generate_sql(question, prefer_model='ollama')
                if result and result.get('success') and result.get('sql'):
                    sql = result['sql']
                    logger.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω SQL —Ñ–æ–ª–ª–±—ç–∫–æ–º ollama: {sql}")
                    return sql
                error_msg = result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞') if isinstance(result, dict) else str(result)
                raise Exception(error_msg)
            except Exception as e2:
                logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SQL –ø–æ—Å–ª–µ —Ñ–æ–ª–ª–±—ç–∫–∞: {e2}")
                raise
    
    async def add_training_example(self, question: str, sql: str, user_id: str, verified: bool = False):
        """
        –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            sql: SQL –∑–∞–ø—Ä–æ—Å
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            verified: –ü—Ä–æ–≤–µ—Ä–µ–Ω –ª–∏ –ø—Ä–∏–º–µ—Ä
        """
        try:
            logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–∞ –æ–±—É—á–µ–Ω–∏—è –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–∞ –≤ –ø–∞–π–ø–ª–∞–π–Ω (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è)
            # –ü–æ–∫–∞ —á—Ç–æ –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º
            logger.info(f"–ü—Ä–∏–º–µ—Ä —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω: {question} -> {sql}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø—Ä–∏–º–µ—Ä–∞: {e}")
            raise
    
    async def get_training_status(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
        
        Returns:
            Dict[str, Any]: –°—Ç–∞—Ç—É—Å –æ–±—É—á–µ–Ω–∏—è
        """
        try:
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –æ–±—É—á–µ–Ω–∏—è
            return {
                "status": "ready",
                "training_examples": 0,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –æ–±—É—á–µ–Ω–∏—è
                "last_training": None,   # –î–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è
                "model_version": "1.0.0"
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
            raise
    
    def is_ready(self) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–∞
        
        Returns:
            bool: –ì–æ—Ç–æ–≤ –ª–∏ —Å–µ—Ä–≤–∏—Å
        """
        return self.pipeline is not None
    
    async def train_on_database_schema(self, db_connection):
        """
        –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ —Å—Ö–µ–º–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            db_connection: –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        """
        try:
            logger.info("–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Å—Ö–µ–º–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
            
            # –û–±—É—á–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞ –Ω–∞ —Å—Ö–µ–º–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            if self.pipeline:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–¥–æ—Ä–æ–≤—å–µ –º–æ–¥–µ–ª–µ–π
                health_status = self.pipeline.run_health_check()
                logger.info(f"–°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–µ–π: {health_status}")
                
                # –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —Å—Ö–µ–º–µ (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è)
                logger.info("–û–±—É—á–µ–Ω–∏–µ –Ω–∞ —Å—Ö–µ–º–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
            else:
                logger.warning("–ü–∞–π–ø–ª–∞–π–Ω –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Å—Ö–µ–º–µ: {e}")
            raise
